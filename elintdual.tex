\documentclass{article}
\title{ALO for Elastic Net with Intercept through Generalized LASSO}
\author{Yuze Zhou}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\begin{document}
\section{Dual Formulation of Elastic Net with Intercept}
\paragraph{}First, to write the optimization problem of elastic net in a matrix form, and denote $D =[0, I]$, the optimization problem becomes:
\begin{center}
$\hat{\beta} = \arg \min\limits_{\beta} \frac{1}{2}||y-X\beta||_{2}^{2} + \lambda_{1}||D\beta||_{1}+\lambda_{2}||D\beta||_{2}^{2}$
\end{center}
\paragraph{}The augmented Lagrangian for the problem is:
\begin{center}
$L = \frac{1}{2}||y-z||_{2}^{2} + \lambda_{1}||\omega||_{1}+\lambda_{2}||\omega||_{2}^{2} + u^{\tau}(z-X\beta) + v^{\tau}(\omega-D\beta)$
\end{center}
\paragraph{}By taking the derivatives with respect to $z$ and $\beta$, we could obtain:
\begin{center}
$0 = \frac{\partial L}{\partial z} = z-y+u$\\
$0 = \frac{\partial L}{\partial \beta} = -X^{\tau}u-D^{\tau}v$
\end{center}
\paragraph{}Since the first column of $X$ is filled with ones and the first column of $D$ is filled with zeros, the first row of $-X^{\tau}u-D^{\tau}v = 0$ gives $\textbf{1}^{\tau} u = 0$ and due to $D = [0,I]$, the rest rows give that $-X_{j}^{\tau}u = v_{j}$. Moreover, since the rest dimensions of $\omega$ is penalized element-wisely in the augmented Lagrangian, we can minimize over $\omega$ by minimizing over each $\omega_{i}, \quad i \geq 2$, that is, we have to minimize $\lambda_{1}|\omega_{i}| + \lambda_{2}\omega_{i}^{2} - u^{\tau}X_{i}\omega_{i}$ for each dimension of $\omega$, where $X_{i}$ denotes the $i$th column of $X$, therefore:
\begin{center}
$\min\limits_{\omega_{i}} \lambda_{1}|\omega_{i}| + \lambda_{2}\omega_{i}^{2} - u^{\tau}X_{i}\omega_{i} $\\
$ $\\
$= \left\{
\begin{aligned}
0 \quad if \quad |u^{\tau}X_{i}| \leq \lambda_{1}\\
-\frac{(\lambda_{1}-|u^{\tau}X_{i}|)^{2}}{4\lambda_{2}} \quad if \quad |u^{\tau}X_{i}| > \lambda_{1}\\
\end{aligned}
\right.
$
\end{center}
\paragraph{}By taking all the above back to the Lagrangian, we obtain the dual problem as:
\begin{center}
$d^{*} = \min\limits_{u} \frac{1}{2}||y-u||_{2}^{2} + \sum\limits_{j: |X_{j}^{\tau}u| > \lambda_{1}}\frac{(\lambda_{1}-|u^{\tau}X_{i}|)^{2}}{4\lambda_{2}}$\\
$subject \quad to \quad \textbf{1}^{\tau}u = 0$
\end{center}
\paragraph{}First denote $f(u) = \sum\limits_{j: |X_{j}^{\tau}u| > \lambda_{1}}\frac{(\lambda_{1}-|u^{\tau}X_{i}|)^{2}}{4\lambda_{2}}$, clearly $f(u)$ is of quadratic form, $f(u) = \frac{1}{2}u^{\tau}Au+a^{\tau}u+b$, where $b$ is a constant and does not matter in the optimization of the dual problem, $A$ and $a$ are:
\begin{center}
$A = \frac{1}{2\lambda_{2}}X_{E}X_{E}^{\tau}$\\
$E := \{i: |X_{i}^{\tau}u| > \lambda \}$
\end{center}
\begin{center}
$a = \frac{\lambda_{1}}{2\lambda_{2}}(\sum\limits_{i:X_{i}^{\tau}<-\lambda_{1}}X_{i}-\sum\limits_{i:X_{i}^{\tau}>\lambda_{1}}X_{i})$
\end{center}
\paragraph{}The dual problem could also be written in a proximal form:
\begin{center}
$\hat{u} = \textbf{prox}_{\tilde{f}}(y)$\\
$\tilde{f} = \textbf{I}(\textbf{1}^{\tau}u=0)f(u) + \textbf{I}(\textbf{1}^{\tau}u \neq 0)\infty$
\end{center}
\paragraph{}After transforming $f(u)$ into a quadratic form, we could write the Lagrangian for the dual problem back again:
\begin{center}
$L = \frac{1}{2}||y-u||_{2}^{2} + \frac{1}{2}u^{\tau}Au+a^{\tau}u+b + \lambda\textbf{1}^{\tau}u$
\end{center}
\paragraph{}By taking the derivative with respect to $u$, we could obtain:
\begin{center}
$\frac{\partial L}{ \partial u} = u - y +Au+a+\lambda\textbf{1} = 0$
\end{center}
\paragraph{}By shifting the terms, $u$ could be written as a formula of $y$ and $\lambda$: $u = (I+A)^{-1}(y-a-\lambda\textbf{1})$, by taking the derivative with respect to $y$ at both sides, we could obtain the Jacobian matrix $J$ of the proximal operator $\textbf{prox}(\tilde{f})$ at $y$ as:
\begin{center}
$J = (I+A)^{-1} -(I+A)^{-1}\textbf{1}\nabla(\hat{\lambda})^{\tau}$
\end{center}
where $\nabla(\hat{\lambda})^{\tau}$ denotes the gradient of $\lambda$ as a function of $y$.
\paragraph{}By taking $u = (I+A)^{-1}(y-a-\lambda\textbf{1})$ back to the Lagrangian, the dual problem will become a second-order equation of $\lambda$:
\begin{center}
$d^{*} = \max\limits_{\lambda} \frac{1}{2}||y-(I+A)^{-1}(y-a-\lambda\textbf{1})||_{2}^{2}+\frac{1}{2}(y-a-\lambda\textbf{1})^{\tau}(I+A)^{-1}A(I+A)^{-1}(y-a-\lambda\textbf{1})+a^{\tau}(I+A)^{-1}(y-a-\lambda\textbf{1})+\lambda\textbf{1}^{\tau}(I+A)^{-1}(y-a-\lambda\textbf{1})$
\end{center}
\paragraph{}More specifically, the second-order term is:
\begin{center}
$\frac{1}{2}\textbf{1}^{\tau}(I+A)^{-2}\textbf{1}+\frac{1}{2}\textbf{1}^{\tau}(I+A)^{-1}A(I+A)^{-1}\textbf{1}-\textbf{1}^{\tau}(I+A)^{-1}\textbf{1}$
\end{center}
and the first-order term is:
\begin{center}
$2\textbf{1}^{\tau}(I+A)^{-1}(y-a)-\textbf{1}^{\tau}(I+A)^{-2}(y-a)-\textbf{1}^{\tau}(I+A)^{-1}A(I+A)^{-1}(y-a)$
\end{center}
\paragraph{}Thus by solving the second-order equation, we could obtain
\begin{center}
$\hat{\lambda} = \frac{2\textbf{1}^{\tau}(I+A)^{-1}(y-a)-\textbf{1}^{\tau}(I+A)^{-2}(y-a)-\textbf{1}^{\tau}(I+A)^{-1}A(I+A)^{-1}(y-a)}{\textbf{1}^{\tau}(I+A)^{-2}\textbf{1}+\textbf{1}^{\tau}(I+A)^{-1}A(I+A)^{-1}\textbf{1}-2\textbf{1}^{\tau}(I+A)^{-1}\textbf{1}}$
\end{center}
and the gradient
\begin{center}
$\nabla(\hat{\lambda}) = \frac{2(I+A)^{-1}\textbf{1}-(I+A)^{-2}\textbf{1}-(I+A)^{-1}A(I+A)^{-1}\textbf{1}}{\textbf{1}^{\tau}(I+A)^{-2}\textbf{1}+\textbf{1}^{\tau}(I+A)^{-1}A(I+A)^{-1}\textbf{1}-2\textbf{1}^{\tau}(I+A)^{-1}\textbf{1}}$\\
\end{center}
\paragraph{}By taking the gradient back to $J = (I+A)^{-1} -(I+A)^{-1}\textbf{1}\nabla(\hat{\lambda})^{\tau} = (I+A)^{-1} -\frac{(I+A)^{-1}\textbf{1}\textbf{1}^{\tau}(I+A)^{-1}}{\textbf{1}^{\tau}(I+A)^{-1}\textbf{1}}$, we could obtain the Jacobian.
\section{Proof of the Equivalence between the primal and the dual solutions}
\paragraph{}First recall the alo formula from the dual approach $y^{/i} = y_{i}-\frac{u_{i}}{J_{ii}} = \frac{J_{ii}-1}{J_{ii}}y_{i}+\frac{1}{J_{ii}}x_{i}\hat{\beta}$ and the primal formula from the primal approach $y^{/i} = x_{i}\hat{\beta} + \frac{H_{ii}}{1-H_{ii}}(x_{i}\hat{\beta}-y_{i}) = -\frac{H_{ii}}{1-H_{ii}}y_{i}+\frac{1}{1-H_{ii}}x_{i}\hat{\beta}$. In the following section, we're going to show that $H+J =I$, thus giving $H_{ii}+J_{ii} = 1$, and that the solutions given by both the primal and the dual approach are equivalent.
\paragraph{}First, using matrix inverse lemma, we could calculate the inverse of $(I+A) = (I+\frac{1}{2\lambda_{2}}X_{E}X_{E}^{\tau})$ as:
\begin{center}
$\begin{aligned}
(I+A)^{-1} &= (I+\frac{1}{2\lambda_{2}}X_{E}X_{E}^{\tau})^{-1}\\
&= I - X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau}
\end{aligned}
$
\end{center}
therefore the matrix $J$ is:
\begin{center}
$
\begin{aligned}
J &= (I+A)^{-1} -\frac{(I+A)^{-1}\textbf{1}\textbf{1}^{\tau}(I+A)^{-1}}{\textbf{1}^{\tau}(I+A)^{-1}\textbf{1}}\\
&= I - X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau} - \frac{(\textbf{1}-X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau}\textbf{1})(\textbf{1}^{\tau}-\textbf{1}^{\tau}X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau})}{\textbf{1}^{\tau}(I-X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau})\textbf{1}}
\end{aligned}
$
\end{center}
\paragraph{}Now recall that $H = [1,X_{E}]([1,X_{E}]^{\tau}[1,X_{E}]+diag(0,2\lambda_{2},\cdots, 2\lambda_{2}))[1,X_{E}]^{\tau}$, by adopting block inverse, we could derive $H$ as:
\begin{center}
$
\begin{aligned}
H &= [1,X_{E}]
\left(
\begin{array}{cc}
n & \textbf{1}^{\tau}X_{E}\\
X_{E}^{\tau}\textbf{1} & X_{E}^{\tau}X_{E} + 2\lambda_{2}I\\
\end{array}
\right)
[1,X_{E}]^{\tau}\\
&= [1,X_{e}]\\
&\left(
\begin{array}{cc}
\frac{1}{\textbf{1}^{\tau}(I-X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau})\textbf{1}} & \frac{-\textbf{1}^{\tau}X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}}{\textbf{1}^{\tau}(I-X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau})\textbf{1}}\\
\frac{-(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau}\textbf{1}}{\textbf{1}^{\tau}(I-X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau})\textbf{1}}&(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}+\frac{(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau}\textbf{1}\textbf{1}^{\tau}X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}}{\textbf{1}^{\tau}(I-X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau})\textbf{1}}\\
\end{array}
\right)\\
&[1,X_{E}]^{\tau}\\
& = X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau} + \frac{(\textbf{1}-X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau}\textbf{1})(\textbf{1}^{\tau}-\textbf{1}^{\tau}X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau})}{\textbf{1}^{\tau}(I-X_{E}(2\lambda_{2}I+X_{E}^{\tau}X_{E})^{-1}X_{E}^{\tau})\textbf{1}}\\
& = I-J
\end{aligned}
$
\end{center}
\paragraph{}Now that we have showed that $H+J=I$, we could also conclude that $J_{ii}+H_{ii}=1$ and that the alo solutions given by both the primal and dual approaches are equivalent.
\end{document}
